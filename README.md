# Awesome-Multimodal-Reasoning

A comprehensive and up-to-date collection of state-of-the-art methods and benchmarks in **multimodal reasoning**. üöÄ Contributions and suggestions are highly encouraged!

## üîß Method

### üí° Prompt-Augmented Inference

+ **Retrieval Meets Reasoning: Even High-school Textbook Knowledge Benefits Multimodal Reasoning**  [[Paper]](https://arxiv.org/abs/2405.20834) ![](https://img.shields.io/badge/May-2024-red) ![](https://img.shields.io/badge/Task-Science-brightgreen)![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-Retrieval_Augmentation-blue)

+ **CUE-M: Contextual Understanding and Enhanced Search with Multimodal Large Language Model**  [[Paper]](https://arxiv.org/abs/2411.12287) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Knowledge-brightgreen)![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-Retrieval_Augmentation-blue)

+ **Retrieval-Augmented Multi-Modal Chain-of-Thoughts Reasoning for Large Language Models**  [[Paper]](https://arxiv.org/abs/2312.01714) ![](https://img.shields.io/badge/Mar-2024-red) ![](https://img.shields.io/badge/Task-Science-brightgreen) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-ICL_Augmentation-blue)

+ **Inference Retrieval-Augmented Multi-Modal Chain-of-Thoughts Reasoning for Language Models**  [[Paper]](https://ieeexplore.ieee.org/document/10888701) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Science-brightgreen) ![](https://img.shields.io/badge/Method-ICL_Augmentation-blue)

+ **Compositional Chain-of-Thought Prompting for Large Multimodal Models**  [[Paper]](https://arxiv.org/abs/2311.17076) ![](https://img.shields.io/badge/Apr-2024-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-Perception_Augmentation-blue)

+ **TextCoT: Zoom In for Enhanced Multimodal Text-Rich Image Understanding**  [[Paper]](https://arxiv.org/abs/2404.09797) ![](https://img.shields.io/badge/Apr-2024-red) ![](https://img.shields.io/badge/Task-Scene-brightgreen) ![](https://img.shields.io/badge/Task-Chart-brightgreen) ![](https://img.shields.io/badge/Method-Perception_Augmentation-blue)

+ **CoCoT: Contrastive Chain-of-Thought Prompting for Large Multimodal Models with Multiple Image Inputs**  [[Paper]](https://arxiv.org/abs/2401.02582) ![](https://img.shields.io/badge/Jan-2024-red) ![](https://img.shields.io/badge/Task-Logic-brightgreen) ![](https://img.shields.io/badge/Method-Perception_Augmentation-blue)
  
+ **Scaffolding Coordinates to Promote Vision-Language Coordination in Large Multi-Modal Models**  [[Paper]](https://arxiv.org/abs/2402.12058) ![](https://img.shields.io/badge/Feb-2024-red) ![](https://img.shields.io/badge/Task-Compositional-brightgreen) ![](https://img.shields.io/badge/Task-Spatial-brightgreen) ![](https://img.shields.io/badge/Method-Perception_Augmentation-blue)
  
+ **PKRD-CoT: A Unified Chain-of-Thought Prompting for Multi-Modal Large Language Models in Autonomous Driving**  [[Paper]](https://arxiv.org/abs/2412.02025) ![](https://img.shields.io/badge/Dec-2024-red) ![](https://img.shields.io/badge/Task-Autonomous_Driving-brightgreen) ![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **See, Think, Confirm: Interactive Prompting Between Vision and Language Models for Knowledge-based Visual Reasoning**  [[Paper]](https://arxiv.org/abs/2301.05226) ![](https://img.shields.io/badge/Jan-2023-red) ![](https://img.shields.io/badge/Task-Knowledge-brightgreen) ![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **A Picture Is Worth a Graph: A Blueprint Debate Paradigm for Multimodal Reasoning**  [[Paper]](https://arxiv.org/abs/2403.14972) ![](https://img.shields.io/badge/Aug-2024-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Task-Science-brightgreen)![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models**  [[Paper]](https://arxiv.org/abs/2402.03877) ![](https://img.shields.io/badge/Sep-2024-red) ![](https://img.shields.io/badge/Task-Math-brightgreen)![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models**  [[Paper]](https://arxiv.org/abs/2310.16436) ![](https://img.shields.io/badge/Oct-2023-red) ![](https://img.shields.io/badge/Task-Science-brightgreen)![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **Mutli-Step Chain-of-Thought in Geometry Problem Solving**  [[Paper]](https://ieeexplore.ieee.org/document/10800087) ![](https://img.shields.io/badge/Sep-2024-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **GNS: Solving Plane Geometry Problems by Neural-Symbolic Reasoning with Multi-Modal LLMs**  [[Paper]](https://ojs.aaai.org/index.php/AAAI/article/view/34679) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models**  [[Paper]](https://arxiv.org/abs/2410.13510) ![](https://img.shields.io/badge/Oct-2024-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **Cantor: Inspiring Multimodal Chain-of-Thought of MLLM**  [[Paper]](https://arxiv.org/abs/2404.16033) ![](https://img.shields.io/badge/Apr-2024-red) ![](https://img.shields.io/badge/Task-Science-brightgreen) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **Thinking Before Looking: Improving Multimodal LLM Reasoning via Mitigating Visual Hallucination**  [[Paper]](https://arxiv.org/abs/2411.12591) ![](https://img.shields.io/badge/Nov-2024-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)
  
+ **MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action**  [[Paper]](https://arxiv.org/abs/2303.11381) ![](https://img.shields.io/badge/Mar-2023-red) ![](https://img.shields.io/badge/Task-Spatial-brightgreen) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Reasoning_Structure_Augmentation-blue)


### üéØ Reward-Guided Inference

### üéì Supervised Fine-Tuning

- **Sherlock: Self-Correcting Reasoning in Vision-Language Models** [[Paper]](https://arxiv.org/abs/2505.22651) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-Self_Correction-blue)


### ü§ñ Reinforcement Fine-Tuning

- **Advancing Multimodal Reasoning Capabilities of Multimodal Large Language Models via Visual Perception Reward**  [[Paper]](https://arxiv.org/abs/2506.07218) ![](https://img.shields.io/badge/Jun-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **WeThink: Toward General-purpose Vision-Language Reasoning via Reinforcement Learning**  [[Paper]](https://www.arxiv.org/abs/2506.07905) ![](https://img.shields.io/badge/Jun-2025-red) ![](https://img.shields.io/badge/Task-Genral-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO**  [[Paper]](https://arxiv.org/abs/2506.07464) ![](https://img.shields.io/badge/Jun-2025-red) ![](https://img.shields.io/badge/Task-Video-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue)

- **Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2506.04207) ![](https://img.shields.io/badge/Jun-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **SynthRL: Scaling Visual Reasoning with Verifiable Data Synthesis**  [[Paper]](https://arxiv.org/abs/2506.02096) ![](https://img.shields.io/badge/Jun-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue)

- **SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2506.01713) ![](https://img.shields.io/badge/Jun-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **GThinker: Towards General Multimodal Reasoning via Cue-Guided Rethinking**  [[Paper]](https://arxiv.org/abs/2506.01078) ![](https://img.shields.io/badge/Jun-2025-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2505.24871) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue)

- **Reinforcing Video Reasoning with Focused Thinking**  [[Paper]](https://arxiv.org/abs/2505.24718) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Video-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue)

- **VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL**  [[Paper]](https://arxiv.org/abs/2505.23977) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Puzzle-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue)

- **Infi-MMR: Curriculum-based Unlocking Multimodal Reasoning via Phased Reinforcement Learning in Multimodal Small Language Models**  [[Paper]](https://arxiv.org/abs/2505.23091) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **Mixed-R1: Unified Reward Perspective For Reasoning Capability in Multimodal Large Language Models**  [[Paper]](https://arxiv.org/abs/2505.24164) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Genral-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **Unsupervised Post-Training for Multi-Modal LLM Reasoning via GRPO**  [[Paper]](https://arxiv.org/abs/2505.22453) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **Omni-R1: Reinforcement Learning for Omnimodal Reasoning via Two-System Collaboration**  [[Paper]](https://arxiv.org/abs/2505.20256) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Omni-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **One RL to See Them All: Visual Triple Unified Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2505.18129) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Genral-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **SophiaVL-R1: Reinforcing MLLMs Reasoning with Thinking Reward**  [[Paper]](https://arxiv.org/abs/2505.17018) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Genral-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models**  [[Paper]](https://arxiv.org/abs/2505.16854) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Genral-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue) ![](https://img.shields.io/badge/Method-Efficient_Reasoning-blue)

- **R1-ShareVL: Incentivizing Reasoning Capability of Multimodal Large Language Models via Share-GRPO**  [[Paper]](https://arxiv.org/abs/2505.16673) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue)

- **G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2505.13426) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Game-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **Unlocking the Potential of Difficulty Prior in RL-based Multimodal Reasoning**  [[Paper]](https://arxiv.org/abs/2505.13261) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Data_Filtering-blue)

- **VideoRFT: Incentivizing Video Reasoning Capability in MLLMs via Reinforced Fine-Tuning**  [[Paper]](https://arxiv.org/abs/2505.12434) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Video-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue)

- **EchoInk-R1: Exploring Audio-Visual Reasoning in Multimodal LLMs via Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2505.04623) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-Omni-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue)

- **X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains**  [[Paper]](https://arxiv.org/abs/2505.03981) ![](https://img.shields.io/badge/May-2025-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **Fast-Slow Thinking for Large Vision-Language Model Reasoning**  [[Paper]](https://arxiv.org/abs/2504.18458) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **Skywork R1V2: Multimodal Hybrid Reinforcement Learning for Reasoning**  [[Paper]](https://arxiv.org/abs/2504.16656) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue)

- **NoisyRollout: Reinforcing Visual Reasoning with Data Augmentation**  [[Paper]](https://arxiv.org/abs/2504.13055) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue)

- **TinyLLaVA-Video-R1: Towards Smaller LMMs for Video Reasoning**  [[Paper]](https://arxiv.org/abs/2504.09641) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Video-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **VL-Rethinker: Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2504.08837) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement**  [[Paper]](https://arxiv.org/abs/2504.07934) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Data_Filtering-blue)

- **VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model**  [[Paper]](https://arxiv.org/abs/2504.07615) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Grounding-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **VideoChat-R1: Enhancing Spatio-Temporal Perception via Reinforcement Fine-Tuning**  [[Paper]](https://arxiv.org/abs/2504.06958) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Video-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **Skywork R1V: Pioneering Multimodal Reasoning with Chain-of-Thought**  [[Paper]](https://arxiv.org/abs/2504.05599) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **Rethinking RL Scaling for Vision Language Models: A Transparent, From-Scratch Framework and Comprehensive Evaluation Scheme**  [[Paper]](https://arxiv.org/abs/2504.02587) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **SpaceR: Reinforcing MLLMs in Video Spatial Reasoning**  [[Paper]](https://arxiv.org/abs/2504.01805) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Video-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue)

- **Improved Visual-Spatial Reasoning via R1-Zero-Like Training**  [[Paper]](https://arxiv.org/abs/2504.00883) ![](https://img.shields.io/badge/Apr-2025-red) ![](https://img.shields.io/badge/Task-Spatial-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue)

- **Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1**  [[Paper]](https://arxiv.org/abs/2503.24376) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Video-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **Video-R1: Reinforcing Video Reasoning in MLLMs**  [[Paper]](https://arxiv.org/abs/2503.21776) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Video-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue)

- **Reason-RFT: Reinforcement Fine-Tuning for Visual Reasoning**  [[Paper]](https://arxiv.org/abs/2503.20752) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Perception-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization**  [[Paper]](https://arxiv.org/abs/2503.12937) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-General-brightgreen) ![](https://img.shields.io/badge/Method-RL_Algorithm-blue) ![](https://img.shields.io/badge/Method-Reward_Design-blue)

- **Reinforcement Learning Outperforms Supervised Fine-Tuning: A Case Study on Audio Question Answering**  [[Paper]](https://arxiv.org/abs/2503.11197) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Audio-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **R1-Onevision: Advancing Generalized Multimodal Reasoning through Cross-Modal Formalization**  [[Paper]](https://arxiv.org/abs/2503.10615) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Data_Synthesis-blue)

- **MM-Eureka: Exploring the Frontiers of Multimodal Reasoning with Rule-based Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2503.07365) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Math-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **R1-Omni: Explainable Omni-Multimodal Emotion Recognition with Reinforcement Learning**  [[Paper]](https://arxiv.org/abs/2503.05379) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Omni-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **R1-Zero's "Aha Moment" in Visual Reasoning on a 2B Non-SFT Model**  [[Paper]](https://arxiv.org/abs/2503.05132) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Spatial-brightgreen) ![](https://img.shields.io/badge/Method-Training_Strategy-blue)

- **Visual-RFT: Visual Reinforcement Fine-Tuning**  [[Paper]](https://arxiv.org/abs/2503.01785) ![](https://img.shields.io/badge/Mar-2025-red) ![](https://img.shields.io/badge/Task-Perception-brightgreen) ![](https://img.shields.io/badge/Method-Reward_Design-blue)


### üîÄ Think with Interleaved-Modal

## üß™ Benchmark

### üß† General Reasoning

- **MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks**  [[Paper]](https://arxiv.org/abs/2505.16459) [[Dataset]](https://huggingface.co/datasets/csegirl/MMMR) ![](https://img.shields.io/badge/May-2025-red) 

- **ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models**  [[Paper]](https://arxiv.org/abs/2505.13444) [[Dataset]](https://huggingface.co/datasets/lytang/ChartMuseum) ![](https://img.shields.io/badge/May-2025-red) 

- **MIRAGE: A Multi-modal Benchmark for Spatial Perception, Reasoning, and Intelligence**  [[Paper]](https://arxiv.org/abs/2505.10604) [[Dataset]](https://huggingface.co/datasets/Mmoment/Mirage_Multimodal_Benchmark) ![](https://img.shields.io/badge/May-2025-red) 

- **R-Bench: Graduate-level Multi-disciplinary Benchmarks for LLM & MLLM Complex Reasoning Evaluation**  [[Paper]](https://arxiv.org/abs/2505.02018) [[Dataset]](https://huggingface.co/datasets/R-Bench/R-Bench) ![](https://img.shields.io/badge/May-2025-red) 

- **VisuLogic: A Benchmark for Evaluating Visual Reasoning in Multi-modal Large Language Models**  [[Paper]](https://arxiv.org/abs/2504.15279) [[Dataset]](https://huggingface.co/datasets/VisuLogic/VisuLogic) ![](https://img.shields.io/badge/Apr-2025-red) 

- **MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in Multimodal Large Language Models**  [[Paper]](https://arxiv.org/abs/2504.05782) [[Dataset]](https://github.com/LanceZPF/MDK12?tab=readme-ov-file#-datasets) ![](https://img.shields.io/badge/Apr-2025-red) 

- **MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models**  [[Paper]](https://arxiv.org/abs/2502.00698) [[Dataset]](https://huggingface.co/datasets/huanqia/MM-IQ) ![](https://img.shields.io/badge/Feb-2025-red) 

- **Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark**  [[Paper]](https://arxiv.org/abs/2501.05444) [[Dataset]](https://huggingface.co/datasets/luckychao/EMMA) ![](https://img.shields.io/badge/Jan-2025-red) 

- **MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks**  [[Paper]](https://arxiv.org/abs/2410.10563) [[Dataset]](https://huggingface.co/datasets/TIGER-Lab/MEGA-Bench) ![](https://img.shields.io/badge/Oct-2024-red) 

- **MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark**  [[Paper]](https://arxiv.org/abs/2409.02813) [[Dataset]](https://huggingface.co/datasets/MMMU/MMMU_Pro) ![](https://img.shields.io/badge/Sep-2024-red) 

- **MLLM-CompBench: A Comparative Reasoning Benchmark for Multimodal LLMs**  [[Paper]](https://arxiv.org/abs/2407.16837) [[Dataset]](https://compbench.github.io/) ![](https://img.shields.io/badge/Jul-2024-red) 

- **CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark**  [[Paper]](https://arxiv.org/abs/2401.11944) [[Dataset]](https://huggingface.co/datasets/m-a-p/CMMMU) ![](https://img.shields.io/badge/Jan-2024-red) 

- **SEED-Bench-2: Benchmarking Multimodal Large Language Models**  [[Paper]](https://arxiv.org/abs/2311.17092) [[Dataset]](https://huggingface.co/datasets/AILab-CVC/SEED-Bench-2) ![](https://img.shields.io/badge/Nov-2023-red) 

- **MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI**  [[Paper]](https://arxiv.org/abs/2311.16502) [[Dataset]](https://huggingface.co/datasets/MMMU/MMMU) ![](https://img.shields.io/badge/Nov-2023-red) 


### ‚ûó Mathematical Reasoning

### üî¨ Scientific Reasoning

### üß© Logical Reasoning

### üß≠ Spatial Reasoning

### üìä Chart Reasoning

### üñºÔ∏è Multi-Image Reasoning

### üé• Video Reasoning

### üîä Audio Reasoning

### üé® Text-to-Image Reasoning

### üîÄ Modal-Interleaved Reasoning

## üóÇÔ∏è Survey

- **Reinforcement Fine-Tuning Powers Reasoning Capability of Multimodal Large Language Models**  [[Paper]](https://arxiv.org/abs/2505.18536) ![](https://img.shields.io/badge/May-2025-red)

- **Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models**  [[Paper]](https://arxiv.org/abs/2505.04921) ![](https://img.shields.io/badge/May-2025-red)

- **Reinforced MLLM: A Survey on RL-Based Reasoning in Multimodal Large Language Models**  [[Paper]](https://arxiv.org/abs/2504.21277) ![](https://img.shields.io/badge/Apr-2025-red)

- **A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond**  [[Paper]](https://arxiv.org/abs/2503.21614) ![](https://img.shields.io/badge/Mar-2025-red)

- **Mind with Eyes: from Language Reasoning to Multimodal Reasoning**  [[Paper]](https://arxiv.org/abs/2503.18071) ![](https://img.shields.io/badge/Mar-2025-red)

- **Multimodal Chain-of-Thought Reasoning: A Comprehensive Survey**  [[Paper]](https://arxiv.org/abs/2503.12605) ![](https://img.shields.io/badge/Mar-2025-red)

- **Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models**  [[Paper]](https://arxiv.org/abs/2503.09567) ![](https://img.shields.io/badge/Mar-2025-red)

- **From System 1 to System 2: A Survey of Reasoning Large Language Models**  [[Paper]](https://arxiv.org/abs/2502.17419) ![](https://img.shields.io/badge/Feb-2025-red)

- **MME-Survey: A Comprehensive Survey on Evaluation of Multimodal LLMs**  [[Paper]](https://arxiv.org/abs/2411.15296) ![](https://img.shields.io/badge/Nov-2024-red)
